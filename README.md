
# Background and Motivation
Approximately 500 million tweets are sent everyday, Of those 500 million, roughly 5 million are geotagged. In other words, the user's device includes location information about where the tweets were sent from. Thus, in this project I analysed roughly 1.1 billion tweets to understand the sentiment around corona as well as used the hashtags as a proxy to track the spread of the virus around the world. 


# Coronavirus twitter analysis
The project analyses tweets regarding Coronavirus through both a geographical and language lense. It does this by extracting country and language information from geotagged tweets that contain corona-related hashtags. The results of the analysis are stored in the 'viz' file. Each hashtag has two related folders. The 'country' represents the country of origin of the hashtag. The 'lang" represents the language of the ambient tweet.  

**Skills Applied:**

1. work with large scale datasets
2. apply python data structures 
3. work with multilingual text
4. use the MapReduce divide-and-conquer paradigm to create parallel code


